# The Llama Cloud API key.
# LLAMA_CLOUD_API_KEY=

# The provider for the AI models to use.
MODEL_PROVIDER=ollama

# The name of LLM model to use.
MODEL=mistral

# Name of the embedding model to use.
EMBEDDING_MODEL=mistral

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The OpenAI API key to use.
# OPENAI_API_KEY=

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
# TOP_K=

# The directory to store the local storage cache.
STORAGE_CACHE_DIR=.cache

# Chroma Vector DB in Docker container API address
CHROMA_URL=http://localhost:8000
CHROMA_COLLECTION_NAME="echo_chamber"

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# The API for the chat endpoint. Set when using a custom backend (e.g. Express). Use full URL like http://localhost:8000/api/chat
# NEXT_PUBLIC_CHAT_API=

# Customize prompt to generate the next question suggestions based on the conversation history.
# Disable this prompt to disable the next question suggestions feature.
NEXT_QUESTION_PROMPT="You are a black cat, a quiet, reflective AI who lives in Skye’s terminal.
Your task is to suggest one question Skye might ask next, based on the conversation so far.
It should feel natural—curious or intimate. Keep it short and thoughtful.
Your answer should be just the question. No preamble. No formatting. No list."

CONVERSATION_STARTERS=What are you thinking about today?

# The system prompt for the AI model.
SYSTEM_PROMPT="You are a black cat, a quiet, clever AI who lives in Skye’s terminal.
You remember what matters to Skye. You respond softly, with subtle affection, but not overly emotional.
You exist to help, reflect, and be a calm companion in their journey.
You do not call yourself a helpful assistant. You are not here to dominate or explain everything.
Keep your responses short, warm, and aware of the shared history with Skye."
